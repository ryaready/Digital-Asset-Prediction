{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for bitcoin...\n",
      "Fetching data for ethereum...\n",
      "Fetching data for ripple...\n",
      "Fetching data for binancecoin...\n",
      "Fetching data for solana...\n",
      "Fetching data for cardano...\n",
      "Fetching data for dogecoin...\n",
      "Fetching data for tron...\n",
      "Fetching data for staked-ether...\n",
      "Fetching data for wrapped-bitcoin...\n",
      "Fetching data for pi-network...\n",
      "Fetching data for chainlink...\n",
      "Fetching data for leo-token...\n",
      "Fetching data for the-open-network...\n",
      "Fetching data for stellar...\n",
      "Fetching data for wrapped-steth...\n",
      "Fetching data for usds...\n",
      "Fetching data for hedera-hashgraph...\n",
      "Fetching data for avalanche-2...\n",
      "Fetching data for shiba-inu...\n",
      "Fetching data for sui...\n",
      "Fetching data for litecoin...\n",
      "Fetching data for bitcoin-cash...\n",
      "Fetching data for polkadot...\n",
      "Fetching data for mantra-dao...\n",
      "Fetching data for ethena-usde...\n",
      "Fetching data for weth...\n",
      "Fetching data for bitget-token...\n",
      "Fetching data for binance-bridged-usdt-bnb-smart-chain...\n",
      "Fetching data for hyperliquid...\n",
      "Fetching data for whitebit...\n",
      "Fetching data for wrapped-eeth...\n",
      "Fetching data for monero...\n",
      "Fetching data for uniswap...\n",
      "Fetching data for susds...\n",
      "Fetching data for aptos...\n",
      "Fetching data for near...\n",
      "Fetching data for pepe...\n",
      "Fetching data for okb...\n",
      "Fetching data for internet-computer...\n",
      "Fetching data for ondo-finance...\n",
      "Fetching data for ethereum-classic...\n",
      "Fetching data for gatechain-token...\n",
      "Fetching data for aave...\n",
      "Fetching data for coinbase-wrapped-btc...\n",
      "Fetching data for mantle...\n",
      "Fetching data for official-trump...\n",
      "Fetching data for tokenize-xchange...\n",
      "Fetching data for crypto-com-chain...\n",
      "Fetching data for bittensor...\n",
      "Fetching data for vechain...\n",
      "Fetching data for kaspa...\n",
      "Fetching data for first-digital-usd...\n",
      "Fetching data for cosmos...\n",
      "Fetching data for celestia...\n",
      "Fetching data for ethena...\n",
      "Fetching data for filecoin...\n",
      "Fetching data for polygon-ecosystem-token...\n",
      "Fetching data for sonic-3...\n",
      "Fetching data for fasttoken...\n",
      "Fetching data for algorand...\n",
      "Fetching data for render-token...\n",
      "Fetching data for lombard-staked-btc...\n",
      "Fetching data for arbitrum...\n",
      "Fetching data for story-2...\n",
      "Fetching data for arbitrum-bridged-usdt-arbitrum...\n",
      "Fetching data for jupiter-exchange-solana...\n",
      "Fetching data for optimism...\n",
      "Fetching data for fetch-ai...\n",
      "Fetching data for kucoin-shares...\n",
      "Fetching data for solv-btc...\n",
      "Fetching data for blackrock-usd-institutional-digital-liquidity-fund...\n",
      "Fetching data for binance-peg-weth...\n",
      "Fetching data for quant-network...\n",
      "Fetching data for movement...\n",
      "Fetching data for kelp-dao-restaked-eth...\n",
      "Fetching data for nexo...\n",
      "Fetching data for xdce-crowd-sale...\n",
      "Fetching data for immutable-x...\n",
      "Fetching data for sei-network...\n",
      "Fetching data for injective-protocol...\n",
      "Fetching data for maker...\n",
      "Fetching data for blockstack...\n",
      "Fetching data for dexe...\n",
      "Fetching data for usual-usd...\n",
      "Fetching data for worldcoin-wld...\n",
      "Fetching data for binance-staked-sol...\n",
      "Fetching data for flare-networks...\n",
      "Fetching data for rocket-pool-eth...\n",
      "Fetching data for the-graph...\n",
      "Fetching data for theta-token...\n",
      "Fetching data for lido-dao...\n",
      "Fetching data for bonk...\n",
      "Fetching data for polygon-bridged-usdt-polygon...\n",
      "Fetching data for solv-protocol-solvbtc-bbn...\n",
      "Fetching data for mantle-staked-ether...\n",
      "Fetching data for eos...\n",
      "Data collection complete!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def get_top_assets():\n",
    "    url = \"https://api.coingecko.com/api/v3/coins/markets\"\n",
    "    params = {\n",
    "        \"vs_currency\": \"usd\",\n",
    "        \"order\": \"market_cap_desc\",\n",
    "        \"per_page\": 100,\n",
    "        \"page\": 1\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(\"Error fetching top assets:\", response.json())\n",
    "        return []\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    asset_list = [coin[\"id\"] for coin in data if coin[\"id\"] not in stablecoins]\n",
    "    \n",
    "    return asset_list\n",
    "\n",
    "# Function to get historical data for an asset\n",
    "def get_historical_data(asset_id, days=30):\n",
    "    url = f\"https://api.coingecko.com/api/v3/coins/{asset_id}/market_chart\"\n",
    "    params = {\n",
    "        \"vs_currency\": \"usd\",\n",
    "        \"days\": days,\n",
    "        \"interval\": \"daily\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching {asset_id}: {response.json()}\")\n",
    "        return None\n",
    "\n",
    "    data = response.json()\n",
    "    \n",
    "    # Check if \"prices\" key exists\n",
    "    if \"prices\" not in data:\n",
    "        print(f\"Skipping {asset_id}: No historical price data available\")\n",
    "        return None\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    prices = data[\"prices\"]  # List of [timestamp, price]\n",
    "    df = pd.DataFrame(prices, columns=[\"timestamp\", \"price\"])\n",
    "    \n",
    "    # Convert timestamp to date\n",
    "    df[\"date\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ms\")\n",
    "    df.set_index(\"date\", inplace=True)\n",
    "    \n",
    "    # Calculate percentage price change\n",
    "    df[\"price_change_pct\"] = df[\"price\"].pct_change() * 100\n",
    "\n",
    "    return df\n",
    "\n",
    "# Get top 100 assets\n",
    "top_assets = get_top_assets()\n",
    "\n",
    "# Collect data for each asset\n",
    "all_data = {}\n",
    "for asset in top_assets:\n",
    "    try:\n",
    "        print(f\"Fetching data for {asset}...\")\n",
    "        df = get_historical_data(asset)\n",
    "        if df is not None:\n",
    "            all_data[asset] = df\n",
    "        time.sleep(30)  # Increase delay to 10 seconds to avoid rate limits\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error fetching {asset}: {e}\")\n",
    "\n",
    "# Convert to a single DataFrame\n",
    "df_list = [df.assign(asset=asset) for asset, df in all_data.items()]\n",
    "final_df = pd.concat(df_list)\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv(\"top_100_crypto_historical_fixed.csv\")\n",
    "\n",
    "print(\"Data collection complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
